2025-01-10 13:43:40,255 - INFO - Loaded hyperparameters: [{'GPU_device': 'cuda:0', 'filter': True, 'num_epochs': 500, 'early_stop': 500, 'num_classes': 2, 'd_state': 16, 'd_conv': 2, 'expand': 8, 'scale_factor': 1, 'batch_size': 256}]. 

2025-01-10 13:43:40,256 - INFO - DriverDistraction 

2025-01-10 13:43:40,404 - INFO - GPU: cuda:0
 model name: BrainMamba2_multibranch
2025-01-10 13:43:45,686 - INFO - ================================================================================
2025-01-10 13:43:45,686 - INFO - Successful Load the Dataset: DriverDistraction
2025-01-10 13:43:45,686 - INFO - ================================================================================
2025-01-10 13:43:45,686 - INFO - Total number of trails: 66197
2025-01-10 13:43:45,686 - INFO -   - Train data shape: (48982, 14, 256), Train label shape: (48982,) (73.99%)
2025-01-10 13:43:45,686 - INFO -   - Validation data shape: (4481, 14, 256), Validation label shape: (4481,) (6.77%)
2025-01-10 13:43:45,686 - INFO -   - Test data shape: (12734, 14, 256), Test label shape: (12734,) (19.24%)
2025-01-10 13:43:45,686 - INFO -   - All train data shape: (53463, 14, 256), All train label shape: (53463,)
--------------------------------------------------------------------------------
2025-01-10 13:47:04,735 - INFO - training set filtered.
2025-01-10 13:47:21,630 - INFO - validation set filtered.
2025-01-10 13:48:10,269 - INFO - testing set filtered.
2025-01-10 13:48:10,269 - INFO - --------------------------------------------------------------------------------
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.branch1.weight: Shape torch.Size([64, 14, 1])
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.branch1.bias: Shape torch.Size([64])
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.branch3.weight: Shape torch.Size([64, 14, 3])
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.branch3.bias: Shape torch.Size([64])
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.branch7.weight: Shape torch.Size([64, 14, 7])
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.branch7.bias: Shape torch.Size([64])
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.fuse.weight: Shape torch.Size([64, 192, 1])
2025-01-10 13:48:11,072 - INFO - Layer input_embedding.fuse.bias: Shape torch.Size([64])
2025-01-10 13:48:11,072 - INFO - Total trainable parameters: 4563606

2025-01-10 13:48:11,073 - INFO - Model Summary: 
 BrainMamba2_multibranch(
  (input_embedding): MultiBranchInputEmbedding(
    (branch1): Conv1d(14, 64, kernel_size=(1,), stride=(1,))
    (branch3): Conv1d(14, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    (branch7): Conv1d(14, 64, kernel_size=(7,), stride=(1,), padding=(3,))
    (fuse): Conv1d(192, 64, kernel_size=(1,), stride=(1,))
  )
  (encoder1): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): SelfSupervisedMambaModel(
      (mamba): Mamba2(
        (in_proj): Linear(in_features=64, out_features=1064, bias=False)
        (conv1d): Conv1d(544, 544, kernel_size=(2,), stride=(1,), padding=(1,), groups=544)
        (act): SiLU()
        (norm): RMSNorm()
        (out_proj): Linear(in_features=512, out_features=64, bias=False)
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
  )
  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (encoder2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (encoder3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))
  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (bottleneck): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): SelfSupervisedMambaModel(
      (mamba): Mamba2(
        (in_proj): Linear(in_features=256, out_features=4160, bias=False)
        (conv1d): Conv1d(2080, 2080, kernel_size=(2,), stride=(1,), padding=(1,), groups=2080)
        (act): SiLU()
        (norm): RMSNorm()
        (out_proj): Linear(in_features=2048, out_features=256, bias=False)
      )
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (2): Linear(in_features=256, out_features=256, bias=True)
  )
  (decoder3): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))
  (decodeMamba3): SelfSupervisedMambaModel(
    (mamba): Mamba2(
      (in_proj): Linear(in_features=256, out_features=4160, bias=False)
      (conv1d): Conv1d(2080, 2080, kernel_size=(2,), stride=(1,), padding=(1,), groups=2080)
      (act): SiLU()
      (norm): RMSNorm()
      (out_proj): Linear(in_features=2048, out_features=256, bias=False)
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (decoder2): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(1,))
  (decodeMamba2): SelfSupervisedMambaModel(
    (mamba): Mamba2(
      (in_proj): Linear(in_features=128, out_features=2096, bias=False)
      (conv1d): Conv1d(1056, 1056, kernel_size=(2,), stride=(1,), padding=(1,), groups=1056)
      (act): SiLU()
      (norm): RMSNorm()
      (out_proj): Linear(in_features=1024, out_features=128, bias=False)
    )
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (decoder1): Conv1d(192, 64, kernel_size=(3,), stride=(1,), padding=(1,))
  (onput_embedding): Conv1d(64, 14, kernel_size=(1,), stride=(1,))
)

2025-01-10 13:48:11,073 - INFO - Training start.
2025-01-10 16:05:18,934 - INFO -  - Channel 1 MSE: 8.625333336453878e-09
2025-01-10 16:05:18,934 - INFO -  - Channel 2 MSE: 1.7529901974455697e-09
2025-01-10 16:05:18,934 - INFO -  - Channel 3 MSE: 6.640351823961055e-09
2025-01-10 16:05:18,934 - INFO -  - Channel 4 MSE: 7.867436480069046e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 5 MSE: 2.3666433257574226e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 6 MSE: 9.10505448814547e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 7 MSE: 5.881933162754649e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 8 MSE: 2.321337788657729e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 9 MSE: 4.184882662627842e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 10 MSE: 3.942929982514443e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 11 MSE: 3.203768805803975e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 12 MSE: 8.115796923391372e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 13 MSE: 3.825237016030769e-09
2025-01-10 16:05:18,935 - INFO -  - Channel 14 MSE: 1.5230231298346553e-08
2025-01-10 16:05:18,935 - INFO -  - Average MSE across all channels computed from Original and Reconstructed ERPs: 3.2446846598421786e-10
